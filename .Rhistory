"u4_5_nfi_supply_ru_bel",
"u4_6_nfi_supply_foreign",
"u4_6_1_nfi_supply_foreign_other",
"nfi_check",
"nfi_check_note",
"x2_cash_limitation",
"x3_credit_cards_limitation",
"x4_debit_cards_limitation",
"x5_mobile_apps_limitation",
"x6_vouchers_limitation",
"x7_other_limitation",
"x8_cash_markup",
"x9_credit_cards_markup",
"x10_debit_cards_markup",
"x11_mobile_apps_markup",
"x12_vouchers_markup",
"x13_other_markup"
)
## Add any changes to the tool?
raw.main <- raw.main %>%
select(-any_of(cols_remove, vars = NULL))
tool.survey <- tool.survey %>%
mutate(datasheet = "main")
############################
##  Clean names and dates ##
###########################
raw.main <- raw.main %>%
rename(submission_time = "_submission_time") %>%
rename_all(~sub("_geolocation","geolocation", .x))
cols_to_drop_main <- c(
tool.survey %>% filter(type == "note") %>% pull(name),      # all note columns
colnames(raw.main)[str_starts(colnames(raw.main), "_")]     # all columns with names starting with underscore
)
raw.main <- raw.main %>% select(-any_of(cols_to_drop_main, vars=NULL)) %>% relocate(uuid)
# fix dates:
date_cols_main <- c("date_assessment","start","end", tool.survey %>% filter(type == "date" & datasheet == "main") %>% pull(name),
"submission_time")
raw.main <- raw.main %>%
mutate_at(date_cols_main, ~ifelse(!str_detect(., '-'), as.character(convertToDateTime(as.numeric(.))), .))
rm(cols_to_drop_main, date_cols_main)
##############################
##  NO CONSENT + DUPLICATES ##
#############################
# check for duplicates
ids <- raw.main$uuid[duplicated(raw.main$uuid)]
if (length(ids)>0) warning("Duplicate uuids detected: ", length(ids))
# add to deletion log
#changed here to remove only the first duplicate
deletion.log.new <- create.deletion.log(raw.main[!duplicated(raw.main$uuid),] %>% filter(uuid %in% ids),enum_colname, "Duplicate") # a brand new deletion log
rm(ids)
# check for no consent
no_consents <- raw.main %>% filter(a4_informed_consent == "no")
if (nrow(no_consents) > 0) warning("No-consent detected: ", nrow(no_consents))
# add to deletion log
if("no_consent_reasons" %in% colnames(raw.main)){
deletion.log.no_consents <- no_consents %>%
mutate(reason = paste0("no consent", ifelse(is.na(no_consent_reasons), "", paste0(": ", no_consent_reasons)))) %>% select(uuid, !!sym(enum_colname), reason)
# translate the no-consents reasons :)
deletion.log.no_consents <- deletion.log.no_consents %>% translate.responses("reason") %>%
mutate(reason = str_to_lower(response.en.from.uk)) %>% select(-response.en.from.uk)
}else{
deletion.log.no_consents <- no_consents %>% create.deletion.log(enum_colname, "no consent")
}
deletion.log.new <- rbind(deletion.log.new, deletion.log.no_consents)
raw.main  <- raw.main[!duplicated(raw.main$uuid,fromLast=TRUE),]
raw.main  <- raw.main[!(raw.main$uuid %in% deletion.log.no_consents$uuid),]
####################################
##  Clean data due to enum errors ##
###################################
#-------------------------------------------------------------------------------
# Addded this piece to add the missing data due to some old version submissions
missing_data <- raw.main %>%
filter(is.na(raw.main["w3_access_stores/no_access_due_to_power_outages"]))
cols_missing_yn <- colnames(raw.main) %>%
str_subset(pattern = "\\_yn")
cols_missing_yn <- cols_missing_yn[1:length(cols_missing_yn)-1]
cols_missing_01 <- c(
"v1_difficulties/storage_during_power_outages",
"w3_access_stores/no_access_due_to_power_outages",
"w3_access_stores/no_access_during_air_alert"
)
missing_data[cols_missing_01] <- "0"
for (col_yn in cols_missing_yn) {
col_next <- substr(col_yn,1,nchar(col_yn)-3)
col_yn_name <- col_yn
missing_data[col_yn_name] <- case_when(missing_data[col_next] != "999" ~ "Yes",
missing_data[col_next] == "999" ~ "No")
}
cleaning.log.missing <- recode.missing(raw.main,c(cols_missing_01,cols_missing_yn),missing_data,
"correction due to old questionnaire version") %>%
distinct() %>%
filter(old.value %!=na% new.value)
int_cols_main  <- tool.survey %>% filter(type %in% c("decimal","integer") & datasheet == "main") %>% pull(name)
cl_999s <- recode.set.NA.if(raw.main, int_cols_main, "999", "replacing 999 with NA")
final_price <- colnames(raw.main) %>%
str_subset(pattern = "\\_final_price")
cols_final_price  <- tool.survey %>% filter(name %in% c(final_price) & datasheet == "main") %>% pull(name)
cl_nan <- recode.set.NA.if(raw.main, cols_final_price, "NaN", "replacing NaN with NA")
cleaning.log <- bind_rows(cleaning.log.missing,cl_999s, cl_nan, cleaning.log)
raw.main <- raw.main %>%
apply.changes(cleaning.log)
# Here we recode labels to variables, which appeared because something wrong went with half of KIIS submissions
kiis_dictionary <- tool.choices %>%
rename("from" = "label::English",
"to" = "name") %>%
subset(select = -list_name)
kiis_dictionary$col <- ".global"
tf <- data.frame( from = c("TRUE","FALSE"),
to = c("1","0"),
col = c(".global",".global")
)
kiis_dictionary <- rbind(kiis_dictionary,tf)
select_one_multiple <- tool.survey %>% filter(str_starts(tool.survey$type, "select_"))
cols_to_recode <- c(colnames(raw.main)[grepl("/",colnames(raw.main))],select_one_multiple$name)
cleaning.log.labels <- recode.label.to.value(raw.main, cols_to_recode, kiis_dictionary$from, kiis_dictionary, "Recoding label to variable")
raw.main <- raw.main %>%
matchmaker::match_df(dictionary = kiis_dictionary, from = "from",
to = "to",
by = "col")
#cleaning.log <- bind_rows(cleaning.log,cleaning.log.labels)
raw.main <- raw.main %>%
apply.changes(cleaning.log.labels)
### Changing location (hromada name) due to enumerator error
location_error <- raw.main %>%
filter(a7_current_hromada == "UA6802005" & a2_1_enum_id =="KIIS_004" & a8_current_settlement == "other")
location_error["a7_current_hromada"] <- "UA6802017"
cleaning.log.location <- location_error %>% select("uuid") %>% mutate(variable = "a7_current_hromada",
old.value="UA6802005", new.value= "UA6802017",
issue= "correction due to enumerator error")
cleaning.log <- bind_rows(cleaning.log,cleaning.log.location)
raw.main <- raw.main %>%
apply.changes(cleaning.log)
##Cleaning KIIS part of data
kiis_dictionary_part2 <- data.frame()
kiis_dictionary_part2 <- tool.choices %>% select(name)
colnames(kiis_dictionary_part2)[1] <- "from"
kiis_dictionary_part2$to <- "1"
kiis_dictionary_part2$col <- ".global"
multiple_choice <- tool.survey %>% filter(str_detect(type, "select_multiple"))
multiple_choice_col <- c(multiple_choice$name)
# Initialize a list to store the cleaning logs
cleaning_logs <- list()
cleaning_logs1 <- list()
# Iterate over each value in multiple_choice_col_values
for (value in multiple_choice_col) {
multiple_choice_col_values <- strsplit(multiple_choice_col, ", ")[[value]]
raw.main.multiple_choice_col <- colnames(raw.main) %>%
str_subset(pattern = paste0(value, "(?!_other)"))
raw.main.multiple_choice_col_1 <- raw.main.multiple_choice_col[-1]
cleaning.log.labels_part2 <- recode.label.to.value(raw.main, raw.main.multiple_choice_col_1, kiis_dictionary_part2$from, kiis_dictionary_part2, "correction due to different type of data")
cleaning_logs1[[value]] <- cleaning.log.labels_part2
raw.main <- raw.main %>%
apply.changes(cleaning_logs1[[value]])
kiis_data <- raw.main[!is.na(raw.main[, raw.main.multiple_choice_col[1]]), ]
cols_to_replace <- names(kiis_data) %in% raw.main.multiple_choice_col_1
kiis_data[, cols_to_replace][is.na(kiis_data[, cols_to_replace])] <- "0"
cleaning.log.kiis_data <- recode.missing(raw.main, c(raw.main.multiple_choice_col_1), kiis_data, "correction due to different type of data") %>%
distinct() %>%
filter(old.value %!=na% new.value)
# Store the cleaning log for each value
cleaning_logs[[value]] <- cleaning.log.kiis_data
}
# Combine all cleaning logs into a single list
cleaning_log_combined <- do.call(rbind, cleaning_logs)
cleaning_log_combined1 <- do.call(rbind, cleaning_logs1)
cleaning_log_combined <- as.data.frame(cleaning_log_combined)
cleaning_log_combined1 <- as.data.frame(cleaning_log_combined1)
raw.main <- raw.main %>%
apply.changes(cleaning_log_combined)
cleaning.log <- bind_rows(cleaning.log,cleaning_log_combined, cleaning_log_combined1, cleaning.log.labels)
### Deleting submissions due to wrong location
#
# submissions_to_delete <- c(
#
#
# )
# wrong_location <- raw.main %>%
#   filter(uuid %in% submissions_to_delete)
# deletion.log.wrong_location <- wrong_location %>% create.deletion.log(enum_colname, "wrong location")
# deletion.log.new <- rbind(deletion.log.new, deletion.log.wrong_location)
#
#
# ## run this to remove wrong_location  ##
#
# raw.main <- raw.main[!(raw.main$uuid %in% deletion.log.wrong_location$uuid),]
#
rm(no_consents, deletion.log.no_consents, cleaning_log_combined, cleaning_log_combined1, cleaning.log.location, cleaning.log.labels)
####################
##  AUDIT CHECKS ##
###################
## Survey durations
# FOR POL: WE WERE NOT GIVEN ACCESS TO AUDIT FILES, so no audit logs will be found
# audits <- load.audit.files(dir.audits, uuids = raw.main$uuid, track.changes = F)
#
# # save.image("environment.RData")
# # load("environment.RData")
#
# if(nrow(audits) == 0) {audits.summary <- tibble(uuid = raw.main$uuid, tot.rt = NA)
# }else{
#   audits.summary <- audits %>%
#     group_by(uuid) %>%
#     group_modify(~process.uuid(.x))
# }
#
# data.audit <- raw.main %>%
#   mutate(duration_mins = difftime(as.POSIXct(end), as.POSIXct(start), units = 'mins'),
#          num_NA_cols = rowSums(is.na(raw.main)),
#          num_dk_cols = rowSums(raw.main == "dont_know", na.rm = T),
#          num_other_cols = rowSums(!is.na(raw.main[str_ends(colnames(raw.main), "_other")]), na.rm = T))  %>%
#  select(uuid, !!sym(enum_colname), start, end, duration_mins, num_NA_cols, num_dk_cols, num_other_cols)
#
# audits.summary <- data.audit %>%
#   left_join(audits.summary, by="uuid") %>% select(-contains("/")) %>%
#   relocate(uuid, duration_mins, num_NA_cols, num_dk_cols, num_other_cols, tot.rt) %>%
#   arrange(duration_mins)
#
# write.xlsx(audits.summary, "output/checking/audits/audits_summary.xlsx")
#
# # follow up with FPs if there are surveys under 10 minutes or above 1 hour
# survey_durations_check <- audits.summary %>% filter(duration_mins < 10 | duration_mins > 60)
# if(nrow(survey_durations_check) > 0){
#   write.xlsx(survey_durations_check, "output/checking/audits/survey_durations.xlsx",
#              zoom = 90, firstRow = T)
# }else cat("\nThere are no survey durations to check :)")
## Soft duplicates (less than 12 different columns?)
res.soft_duplicates <- find.similar.surveys(raw.main, tool.survey, uuid = "uuid") %>%
filter(number_different_columns <= 12)
if(nrow(res.soft_duplicates) > 0){
write.xlsx(res.soft_duplicates, make.filename.xlsx("output/checking/audit/", "soft_duplicates"))
}else cat("\nThere are no soft duplicates to check :)")
## Soft duplicates (less than 10 different columns?)
res.soft_duplicates <- find.similar.surveys(raw.main, tool.survey, uuid = "uuid") %>%
filter(number_different_columns <= 10)
if(nrow(res.soft_duplicates) > 0){
write.xlsx(res.soft_duplicates, make.filename.xlsx("output/checking/audit/", "soft_duplicates"))
}else cat("\nThere are no soft duplicates to check :)")
# DECISIONs:
# interviews that were too fast and decided to be removed based on these uuids:
ids <- c(
)
deletion.log.too.fast <- create.deletion.log(raw.main %>% filter(uuid %in% ids),
enum_colname, "Survey duration deemed too fast.")
# soft duplicates to remove:
ids <- c(
"4246a4a5-45b8-46d8-ab8b-a5055208f5c4",
"0aed463a-20ae-43f7-b74c-266762bd7297"
)
deletion.log.softduplicates <- create.deletion.log(raw.main %>% filter(uuid %in% ids),
enum_colname, "Soft duplicate")
# incomplete submissions to remove:
ids <- c(
)
deletion.log.incomplete <- create.deletion.log(raw.main %>% filter(uuid %in% ids), enum_colname, "Incomplete submission")
deletion.log.audits <- bind_rows(deletion.log.too.fast, deletion.log.softduplicates, deletion.log.incomplete)
deletion.log.new <- bind_rows(deletion.log.new, deletion.log.audits)
#################################################
##   removing fast submissions and duplicates  ##
raw.main  <- raw.main[! (raw.main$uuid  %in% deletion.log.audits$uuid),]
#################################################
rm(ids, deletion.log.too.fast, deletion.log.softduplicates)
library(readxl)
to_translate <- read_excel("output/checking/responses/to_translate.xlsx")
View(to_translate)
#cleaning.log <- data.frame() #### Please remove if you hve loops
cleaning.log.other <- data.frame()
or.request <- load.requests(dir.requests,  make.short.name("other_requests", no_date = T), sheet = "Sheet2")
or.edited  <- load.requests(dir.responses, make.short.name("other_response", no_date = T),
sheet = "Sheet2", validate = T) # specify Sheet2 because the first one is a readme
or.edited$loop_index <- NA   #added this to overcome the problem of not finding loop_index column
if (nrow(or.request) != nrow(or.edited)) stop("Number of rows differs between or.request and or.edited!")
or.true.and.recode <- filter(or.edited, check == 1)
if (nrow(or.true.and.recode) > 0){
cat(paste0("Multiple columns selected in ", nrow(or.true.and.recode)," or.edited entries:\n",
paste0(or.true.and.recode %>% pull(uuid), collapse = "\n")), sep = "\n")
if(any(or.true.and.recode$ref.type != "select_multiple")) stop("One of those is not a select_multiple!!!")
# if(any(!is.na(or.true.and.recode$loop_index))) stop("Deal with loop code INSTEAD of UUID-LOOP-INDEX")
issue <- "Recoding other response"
for(r in 1:nrow(or.true.and.recode)){
x <- or.true.and.recode[r,]
# get list of choices from other response
if (str_detect(x$existing.v, ";")) {
choices <- str_trim(str_split(x$existing.v, ";")[[1]])
} else {
choices <- str_trim(str_split(x$existing.v, "\r\n")[[1]])
}
choices <- choices[choices!=""]
if(is.na(x$loop_index)){
old.value <- as.character(raw.main[raw.main$uuid==x$uuid[1], x$ref.name[1]])
} else {
old.value <- as.character(raw.loop1[raw.loop1$loop_index==x$loop_index[1], x$ref.name[1]])
}
l <- str_split(old.value, " ")[[1]]
# add to the cleaning log each choice in the other response
for (choice in choices){
# set corresponding variable to "1" if not already "1"
list.name <- get.choice.list.from.name(x$ref.name)
new.code <- filter(tool.choices, list_name==list.name & !!sym(label_colname)==choice)
if (nrow(new.code)!=1){
warning(paste0("Choice is not in the list. UUID: ", x$uuid,"; recode.into: ", choice))
return("err")
}
variable.name <- paste0(x$ref.name, "/", new.code$name)
if(is.na(x$loop_index)){
if (variable.name %in% colnames(raw.main)){
old.boolean <- raw.main[[variable.name]][raw.main$uuid==x$uuid[1]]
} else warning("Column not found")
} else {
if (variable.name %in% colnames(raw.loop1)){
old.boolean <- raw.loop1[[variable.name]][raw.loop1$loop_index==x$loop_index[1]]
} else warning("Column not found")
}
df <- data.frame(uuid=x$uuid, loop_index=x$loop_index, variable=variable.name, issue=issue,
old.value=old.boolean, new.value="1")
cleaning.log.other <<- rbind(cleaning.log.other, df)
l <- unique(c(l, new.code$name))
}
# update cumulative variable
new.value <- paste(sort(l), collapse=" ")
df <- data.frame(uuid=x$uuid, loop_index=x$loop_index, variable=x$ref.name, issue=issue,
old.value=old.value, new.value=new.value)
cleaning.log.other <<- rbind(cleaning.log.other, df)
}
or.edited <- or.edited %>% filter(check == 2)
}
or.true <- filter(or.edited, !is.na(true.v))
or.recode <- filter(or.edited, !is.na(existing.v))
or.remove <- filter(or.edited, !is.na(invalid.v))
#cleaning.log.other <- subset(cleaning.log.other, select = -loop_index)
# 1) handle invalid
print(paste("Number of responses to be deleted:", nrow(or.remove)))
if (nrow(or.remove)>0){
for (r in 1:nrow(or.remove)) {
if(is.na(or.remove$loop_index[r])){
add.to.cleaning.log.other.remove(raw.main, or.remove[r,])
#      recode.others(raw.main, or.remove[r,])
} else{
add.to.cleaning.log.other.remove(raw.loop1, or.remove[r,])
}
}
}
# 2) handle recoding
print(paste("Number of responses to be recoded:", nrow(or.recode)))
if (nrow(or.recode)>0){
for (r in 1:nrow(or.recode)) {
if(is.na(or.recode$loop_index[r])){
add.to.cleaning.log.other.recode(raw.main, or.recode[r,])
} else {
add.to.cleaning.log.other.recode(raw.loop1, or.recode[r,])
}
}
}
# 3) handle true\
or.true <- rbind(or.true, or.true.and.recode)
print(paste("Number of responses to be translated:", nrow(or.true)))
t <- or.true %>%
mutate(issue = "Translating other responses") %>%
rename(variable=name, old.value=response.uk, new.value=true.v) %>%
select(uuid, variable,issue, old.value, new.value)
cleaning.log.other <- rbind(cleaning.log.other, t, to_translate)
raw.main <- raw.main %>%
apply.changes(cleaning.log.other)
cleaning.log <- bind_rows(cleaning.log, cleaning.log.other  )
### ADD translation cleaning
################
##  Outliers ##
###############
prices <- c(
"b3_bread_price",
"c3_eggs_price",
"d3_milk_price",
"e3_potatoes_price",
"f3_carrots_price",
"g3_onions_price",
"h3_cabbage_price",
"i3_chicken_price",
"j3_oil_price",
"k3_flour_price",
"l3_rice_price",
"m3_buckwheat_price",
"n3_water_price",
"y3_cereal_porridge_price",
"o3_diapers_price",
"p3_body_soap_price",
"r3_laundry_soap_price",
"q3_powder_price",
"s3_toothpaste_price",
"t3_pads_price"
)
prices_final <- paste(prices,"_final_price",sep="")
# save.image(file = "Environment.RData")
# load("Environment.RData")
cleaning.log.outliers <- data.frame()
# define columns to check for outliers
cols.integer_main <- filter(tool.survey, type %in% c("decimal","integer"))
cols.integer_raw.main <- cols.integer_main[cols.integer_main$name %in% colnames(raw.main),] %>% pull(name)
cols.integer_raw.main <- cols.integer_raw.main[!cols.integer_raw.main %in% prices]
cols.integer_raw.main <- c(cols.integer_raw.main,prices_final)
outlier.recode <- load.requests(dir.responses, make.short.name("outliers_response", no_date = T))
outlier.check <- load.requests(dir.requests, make.short.name("outliers_requests", no_date = T))
if (nrow(outlier.check) != nrow(outlier.recode)) warning("Number of rows are not matching")
cleaning.log.outliers <- outlier.recode %>%
select(uuid,loop_index,variable,issue,old.value,new.value) #%>%
#filter(is.na(new.value))
cleaning.log.outliers <- subset(cleaning.log.outliers, select = -loop_index)
#Added the following line to convert to character, so the apply.changes can work properly
raw.main[cols.integer_raw.main] <- sapply(raw.main[cols.integer_raw.main],as.character)
raw.main <- raw.main %>%
apply.changes(cleaning.log.outliers)
cleaning.log <- rbind(cleaning.log,cleaning.log.outliers)
raw.main <- raw.main %>%
mutate(b3_bread_price_final_price = b3_bread_price %_/_% b3_1_bread_size * 500,
c3_eggs_price_final_price = c3_eggs_price %_/_% c3_1_eggs_size * 10,
d3_milk_price_final_price = d3_milk_price %_/_% d3_1_milk_size * 0.9,
e3_potatoes_price_final_price = e3_potatoes_price %_/_% e3_1_potatoes_size * 1,
f3_carrots_price_final_price = f3_carrots_price %_/_% f3_1_carrots_size * 1,
g3_onions_price_final_price = g3_onions_price %_/_% g3_1_onions_size * 1,
h3_cabbage_price_final_price = h3_cabbage_price %_/_% h3_1_cabbage_size * 1,
i3_chicken_price_final_price = i3_chicken_price %_/_% i3_1_chicken_size * 1,
j3_oil_price_final_price = j3_oil_price %_/_% j3_1_oil_size * 0.9,
k3_flour_price_final_price = k3_flour_price %_/_% k3_1_flour_size * 1,
l3_rice_price_final_price = l3_rice_price %_/_% l3_1_rice_size * 1,
m3_buckwheat_price_final_price = m3_buckwheat_price %_/_% m3_1_buckwheat_size * 1,
n3_water_price_final_price = n3_water_price %_/_% n3_1_water_size * 1.5,
y3_cereal_porridge_price_final_price = y3_cereal_porridge_price %_/_% y3_1_cereal_porridge_size * 200,
o3_diapers_price_final_price = o3_diapers_price %_/_% o3_1_diapers_size * 50,
p3_body_soap_price_final_price = p3_body_soap_price %_/_% p3_1_body_soap_size * 75,
r3_laundry_soap_price_final_price = as.numeric(r3_laundry_soap_price) %_/_% r3_1_laundry_soap_size * 200,
q3_powder_price_final_price = q3_powder_price %_/_% q3_1_powder_size * 500,
s3_toothpaste_price_final_price = s3_toothpaste_price %_/_% s3_1_toothpaste_size * 75,
t3_pads_price_final_price = t3_pads_price %_/_% t3_1_pads_size * 10)
#########################
##  Remove PII columns ##
########################
# finalize cleaning log:
cleaning.log <- cleaning.log %>% distinct() %>%
#filter(old.value %!=na% new.value) %>%
left_join(raw.main %>% select(uuid, any_of(enum_colname)))
if (length(list.files(make.filename.xlsx("output/cleaning_log", "cleaning_log", no_date = T))) > 0) {
cleaning.log.previous <- read_xlsx(make.filename.xlsx("output/cleaning_log", "cleaning_log"))
cleaning.log.whole <- rbind(cleaning.log.previous, cleaning.log)
} else cleaning.log.whole <- cleaning.log
# Output Cleaning Log
write.xlsx(cleaning.log, make.filename.xlsx("output/cleaning_log", "cleaning_log", no_date = T), overwrite = T)
# Output deletion Log
write.xlsx(deletion.log.new, make.filename.xlsx("output/deletion_log", "deletion_log", no_date = T), overwrite = T)
pii.to.remove_main <- c(
"a10_name_retailer",
"a11_branch_retailer",
"a12_phone_number",
"deviceid",
"audit",
"audit_URL",
"z4_like_name_retailer",
"z5_like_phone_number",
"z6_like_hromada",
"comments_enumerators"
)
new.main.removed  <- raw.main %>% select(-any_of(pii.to.remove_main))
# All data write excel
datasheets <- list("main" = raw.main
)
write.xlsx(datasheets, make.filename.xlsx("output/data_log", "full_data"), overwrite = T,
zoom = 90, firstRow = T)
# final (pii removed)
datasheets_anon <- list("main" = new.main.removed
)
raw.main <- raw.main %>% select(-any_of(pii.to.remove_main))
write.xlsx(datasheets_anon, make.filename.xlsx("output/final", "final_clean_data"), overwrite = T,
zoom = 90, firstRow = T)
#######################
#Summary cleaning log
#######################
## Changed Variables
cleaning.log$variable_clean <- gsub("\\/.*","",cleaning.log$variable)
cleaning_count <- cleaning.log %>% count(variable_clean) %>% rename(observations_affected = "n")
cleaning <- cleaning.log[!duplicated(cleaning.log[c("issue", "variable_clean")]),]
cleaning <- aggregate(issue ~ variable_clean, unique(cleaning), paste, collapse = ", ")
cleaning <- cleaning %>% left_join(cleaning_count, by = "variable_clean")
cleaning.log$variable_clean <- NULL
cleaning <- cleaning %>% rename(variable = "variable_clean", action = "issue")
## Removed Variables (add or remove loops)
total_columns_rawmain <- colnames(read_xlsx("data/inputs/kobo_export/UKR2203_JMMI_Questionnaire_Retailers_R14_10MAY2023_OS_WFP.xlsx", sheet = 1, col_types = "text")) %>% unique
#total_columns_rawloop1 <- colnames(read_xlsx("data/inputs/kobo_export/ROM_PP2_rawdata.xlsx", sheet = 2, col_types = "text")) %>% unique
final_columns_rawmain <- colnames(raw.main) %>% unique
#final_columns_rawloop1 <- colnames(raw.loop1) %>% unique
removed_columns_main <- setdiff(total_columns_rawmain, final_columns_rawmain)
#removed_columns_loop1  <- setdiff(total_columns_rawloop1, final_columns_rawloop1)
##update the removed columns depending on number of loops
#removed_columns <- c(removed_columns_main,removed_columns_loop1)
cleaning_removed <- data.frame(variable = removed_columns_main, action = "Columns removed", observations_affected = NA)
cleaning <- rbind(cleaning, cleaning_removed)
## Variables not changed
cleaning_untouched <- setdiff(tool.survey %>% pull(name),cleaning_count$variable_clean)
cleaning_not_changed <- data.frame(variable = cleaning_untouched, action = "Columns not changed", observations_affected = NA)
cleaning <- rbind(cleaning, cleaning_not_changed)
##Variables added
added_columns_main <- setdiff(final_columns_rawmain,total_columns_rawmain)
#added_columns_loop1  <- setdiff( final_columns_rawloop1,total_columns_rawloop1)
if("uuid"%in%added_columns_main){
if("submission_time"%in%added_columns_main){
added_columns_main <- added_columns_main[!added_columns_main %in% c("uuid","submission_time")]
}
}
#if("uuid"%in%added_columns_loop1){
#  if("parent_index"%in%added_columns_loop1){
#    added_columns_loop1 <- added_columns_loop1[!added_columns_loop1 %in% c("uuid","parent_index")]
#  }
#}
#added_columns <- c(added_columns_main)
#cleaning_added <- data.frame(variable = added_columns, action = "Columns added", observations_affected = NA)
#cleaning <- rbind(cleaning, cleaning_added)
write.xlsx(cleaning, "output/cleaning_log/summary.xlsx")
